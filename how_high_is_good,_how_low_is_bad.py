# -*- coding: utf-8 -*-
"""How High is Good, How Low is Bad.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Cfhws2U4_gU61DdGxHKy9Js6x84YuoD-

# 1. Setting Up
"""

!pip install gensim
!pip install numpy

import numpy
from numpy import linalg
import pandas as pd

!wget 'https://huggingface.co/stanfordnlp/glove/resolve/main/glove.42B.300d.zip'

!unzip glove.42B.300d.zip
glove_file = 'glove.42B.300d.txt'
from gensim.models import KeyedVectors
glove = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)

"""# 2) Emotional Valence

Conceptual Metaphor Theory posits that we use concrete domains of knowledge to think and talk about more abstract domains. One example of a concrete domain is orientation in space (e.g. horizontal or vertical orientation). According to experimental and linguistic evidence for example, we understand emotional valence (good/bad) in terms of vertical orientation (up/down). This leads to expression such as "feeling up" meaning feeling good and experiments where.

Projecting emotional valence words onto a semantic scale (up-down). The higher the dotproduct of a word, the closer to the 'up' side of the scale, the lower the dotproduct of a word, the closer to the 'down' side of the scale.
"""

up_down = model['up'] - model['down'] # semantic scale 1
high_low = model['high'] - model['low'] # semantic scale 2

valence = ['worst', 'worse', 'better', 'best'] #target domain vocabulary to project

up_down_dots = [] #empty list for projections on up/down scale
high_low_dots = [] #empty list for projections on high/low scale

len(high_low)

len(model['worse'])

"""#### Up/Down Projections"""

for i in valence: #get the dotproduct for each word in valence list
  dotproduct = numpy.dot(model[i], up_down)
  up_down_dots.append(dotproduct) #write dotproduct to list
#create a df with the words and their dotproducts
up_down_projections = pd.DataFrame(list(zip(valence, up_down_dots)),
                          columns = ['valence', 'dotproduct'])
up_down_projections.sort_values('dotproduct') #order words by dotproduct value

"""#### High/Low Projections"""

#repeat the same for high/low scale
for i in valence:
  dotproduct = numpy.dot(model[i], high_low)
  high_low_dots.append(dotproduct)
high_low_projections = pd.DataFrame(list(zip(valence, high_low_dots)),
                                    columns = ['valence', 'dotproduct'])
high_low_projections.sort_values('dotproduct')

"""# 3) Visualisation

Visualisation of the target domain tokens onto the semantic scale.
--> to come
"""